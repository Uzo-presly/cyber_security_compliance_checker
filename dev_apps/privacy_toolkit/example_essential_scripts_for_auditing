Create a folder named privacy_toolkit/ and place each of these three set of script file in it:

Summary of Use Cases
Tool			Used For				When to Use						Output
Encryption Tool		Secure PII			Before storing/sharing sensitive data				Encrypted text
Dummy CRM		Storing customer data		Managing customer records					SQLite DB
Consent Generator	Get legal consent		Before data processing					Text file or screen output

# 1. Sample Python Encryption Script
# ----------------------------------
# This script demonstrates how to encrypt and decrypt sensitive data using Fernet symmetric encryption.
# Use this to encrypt files or sensitive strings like emails, phone numbers, etc.

from cryptography.fernet import Fernet

# Generate and store this key securely!
key = Fernet.generate_key()
cipher = Fernet(key)

# Sample data to encrypt
data = "user@example.com"
print("Original Data:", data)

# Encrypt the data
encrypted = cipher.encrypt(data.encode())
print("Encrypted:", encrypted)

# Decrypt the data
decrypted = cipher.decrypt(encrypted).decode()
print("Decrypted:", decrypted)


# 2. Dummy SQLite CRM Example
# ---------------------------
# A very basic CRM system that stores customer PII securely.
# Note: In real applications, you'd want to hash or encrypt PII where needed.

import sqlite3

# Connect to SQLite DB (or create one)
conn = sqlite3.connect("crm.db")
cursor = conn.cursor()

# Create a customers table
cursor.execute('''
CREATE TABLE IF NOT EXISTS customers (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    email TEXT UNIQUE,
    phone TEXT,
    consent BOOLEAN DEFAULT 0
)
''')

# Insert dummy customer data
cursor.execute("INSERT INTO customers (name, email, phone, consent) VALUES (?, ?, ?, ?)",
               ("Jane Doe", "jane@example.com", "555-0101", True))

conn.commit()
print("Customer data added.")

# Retrieve and display data
for row in cursor.execute("SELECT * FROM customers"):
    print(row)

conn.close()


# 3. Tools to Generate Consent Forms Dynamically
# ----------------------------------------------
# A dynamic tool using string.Template to generate custom consent forms for clients

from string import Template

def generate_consent_form(name, service, organization):
    form_template = Template("""
    CONSENT FORM
    -------------
    I, $name, hereby give $organization the permission to collect and use my personal information
    for the purpose of $service, in accordance with data protection regulations.

    Signature: ____________________
    Date: _________________________
    """)
    return form_template.substitute(name=name, service=service, organization=organization)

print(generate_consent_form("Jane Doe", "email marketing", "Acme Corp"))


# 4. Explanation: Adding Intelligence to cyber_audit_runner.py
# ------------------------------------------------------------
# Your audit script currently checks for exact keywords. This is powerful but limited:
#
# a. Categorizing Keywords:
#    Instead of treating "name" and "password" the same, you could tag them:
#      - PII: name, phone, address
#      - Secrets: password, api_key, token
#      - Compliance risk: login_url, redirect, consent
#
# b. Use AI/LLM:
#    Instead of only finding the word "password", AI can analyze context:
#      → e.g., detect emails that violate consent, or where patient info is overly exposed.
#    You could send chunks of a document to a language model (like me) to ask:
#      "Does this violate GDPR?"
#
#    That is 'adding intelligence'. It transforms static keyword scan into dynamic context-aware analysis.
#
# Summary of What We've Built:
# ----------------------------
# ✅ Python encryption tool for PII
# ✅ SQLite CRM sample to store user info
# ✅ Consent form generator
# ✅ Guide to scale static scans into intelligent audit
#
# How to Know It's Working:
# --------------------------
# ✅ Encryption: see encrypted/decrypted output matching original
# ✅ CRM: view entries with SELECT query after insertion
# ✅ Consent: printed template should contain correct name/service/org
# ✅ Intelligence: improvement shows up when false positives drop, and meaningful issues are found

# Tip: Bundle these in one folder named `privacy_toolkit/` and run each with:
# python3 filename.py
